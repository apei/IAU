<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><title>4.2. Metodologías y técnicas de DCU</title><link rel="stylesheet" type="text/css" href="style.css"/><meta name="generator" content="DocBook XSL Stylesheets V1.76.1-RC2"/></head><body><div class="section" title="4.2. Metodologías y técnicas de DCU"><div class="titlepage"><div><div><h1 class="title"><a id="ch04b"/>4.2. Metodologías y técnicas de DCU</h1></div></div></div><p>
  		El DCU, como filosofía de diseño, engloba o se relaciona con un heterogéneo conjunto de metodologías y técnicas que comparten un objetivo común: 
  		conocer y comprender las necesidades, limitaciones, comportamiento y características del usuario, involucrando en muchos casos a usuarios 
  		potenciales o reales en el proceso.
  	</p><p>
  		Este apartado pretende servir de guía metodológica, respondiendo a preguntas fundamentales sobre cada técnica: su descripción 
  		(<span class="strong"><strong>qué</strong></span>), su procedimiento (<span class="strong"><strong>cómo</strong></span>), su ubicación en el ciclo del producto 
  		(<span class="strong"><strong>cuándo</strong></span>), y qué limitaciones o problemas pueden presentar.
  	</p><div class="section" title="4.2.1. Test de usuarios"><div class="titlepage"><div><div><h2 class="title"><a id="ch04b1"/>4.2.1. Test de usuarios</h2></div></div></div><div class="section" title="4.2.1.1. Qué"><div class="titlepage"><div><div><h3 class="title"><a id="d0e1278"/>4.2.1.1. Qué</h3></div></div></div><p>
  				El test de usuarios es la prueba reina del DCU, ya que representa la mejor forma de evaluar la usabilidad de un diseño. Estas pruebas 
  				se basan en la observación de cómo un grupo de usuarios llevan a cabo una serie de tareas encomendadas por el evaluador, analizando 
  				los problemas de usabilidad con los que se encuentran (Hassan-Montero; Martín-Fernández; 2003a).
  			</p><p>
  				Aún cuando el diseñador tenga amplios conocimientos sobre usabilidad, resulta recomendable evaluar el diseño con usuarios. Esto se debe 
  				a que, conforme más tiempo dedica un diseñador a un proyecto, menor es su perspectiva y más difícilmente detectará posibles problemas. 
  				Podemos decir que gran parte de lo que el diseñador percibe cuando mira su propia obra, es una construcción mental; ve aquello que tiene 
  				en mente, no aquello que sus usuarios tendrán ante sus ojos.
  			</p></div><div class="section" title="4.2.1.2. Cómo"><div class="titlepage"><div><div><h3 class="title"><a id="d0e1285"/>4.2.1.2. Cómo</h3></div></div></div><p>
  				El número de participantes que son necesarios para detectar el 100% de los problemas (más importantes) de usabilidad de un diseño se 
  				encuentra en torno a 15. Nielsen (2000) recomienda que, en vez de hacer una prueba con 15 participantes, es mejor llevar a cabo tres 
  				pruebas con 5 participantes por cada una, repartidas en diferentes momentos del proceso de desarrollo. Como Nielsen (2000) defiende, 
  				el objetivo de estas pruebas es mejorar de forma iterativa la usabilidad de la aplicación, por lo que cada prueba con 5 participantes 
  				nos ofrecerá suficiente información para mejorar la solución de diseño, aún cuándo no nos permita detectar el 100% de los problemas 
  				de usabilidad.
  			</p><p>
  				En el reclutamiento de participantes debemos asegurarnos de que los elegidos tienen perfiles acordes con los usuarios reales o 
  				potenciales del sitio web, muestran interés por el tipo de sitio web a evaluar y, a ser posible, tienen experiencia usando sitios 
  				web de naturaleza similar (Hassan-Montero; 2007a). Este reclutamiento de participantes, como en cualquier técnica de DCU que implique 
  				la participación de usuarios, sigue tres pasos: determinar la audiencia del sitio web a evaluar, localizar a miembros representativos 
  				de esa audiencia, y convencerles para participar (Kuniavsky; 2003). El que los participantes estén motivados resulta crucial para el 
  				éxito de la prueba. Por tanto, cuando los participantes no sean amigos, familiares o compañeros de trabajo, será muy importante 
  				ofrecerles algún tipo de remuneración o recompensa por su colaboración en la prueba.
  			</p><p>
  				Cada uno de los participantes realizará la prueba por separado, y durante cada prueba deberemos registrar toda aquella información 
  				relevante para el posterior análisis del comportamiento del usuario. Para esto se puede utilizar desde un bloc de notas, hasta 
  				grabaciones de vídeo del usuario, pasando por aplicaciones que registren las acciones del usuario sobre la interfaz.
  			</p><p>
  				La primera impresión que se lleve el participante al mostrarle el diseño supone una información muy valiosa sobre su usabilidad. Los usuarios, 
  				ante una página web, juzgan lo que ven y toman decisiones intuitivas en muy poco tiempo (véase apartado sobre Cognición), juicios y decisiones 
  				que resultan de gran relevancia para entender la capacidad comunicativa del diseño. Por ello, antes de comenzar formalmente el test se recomienda 
  				llevar a cabo lo que Perfetti (2005) denomina un <span class="quote">“<span class="quote">test de 5 segundos</span>”</span>. Este método consiste en ofrecer al participante un contexto 
  				y objetivos concretos (ej.: “Te encuentras en época de exámenes, y necesitas saber si hoy estará la biblioteca abierta por la tarde”), y a 
  				continuación mostrarle la página durante un periodo de cinco segundos. Después se le solicita al participante que exprese todo aquello que 
  				recuerda de la página que ha visto. Esta prueba también se puede llevar a cabo sin ofrecer objetivo o contexto alguno al participante, 
  				mostrándole la página durante 5 segundos y preguntándole posteriormente cuál ha sido su primera impresión, qué contenidos cree que ofrece o 
  				puede encontrar en ese sitio web, permitiéndonos de esta forma evaluar la capacidad autoexplicativa de su diseño visual.
  			</p><p>
  				A continuación podemos comenzar la prueba completa, en la que solicitaremos al participante una serie de tareas a realizar sobre el sitio web, 
  				analizando los errores que cometa, el tiempo empleado y su satisfacción final una vez finalice la tarea. Es decir, esta es una prueba destinada 
  				a medir tanto la usabilidad objetiva (qué y cómo actúa el usuario), como la usabilidad subjetiva (cómo de fácil ha percibido la tarea) 
  				(recordemos el apartado sobre <a class="xref" href="ch02.html#ch02a" title="2.1. La experiencia del usuario">Sección 2.1, “La experiencia del usuario”</a>).
  			</p><p>
  				Según Kuniavsky (2003), algunos requisitos que deben cumplir las tareas encomendadas al participante son:
  			</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>
  						Ser razonables: Es decir, tareas típicas que un usuario real llevaría a cabo.
  					</p></li><li class="listitem"><p>
  						Estar descritas en términos de objetivos finales: La tarea debe contextualizarse bajo un objetivo o motivación mayor.
  					</p></li><li class="listitem"><p>
  						Ser específicas: La tarea no puede se demasiado genérica, sino que debe describir objetivos concretos con el fin de poder comparar 
  						los problemas encontrados con los del resto de participantes.
  					</p></li><li class="listitem"><p>
  						Ser factibles: Encomendar al usuario tareas irrealizables no aporta información útil sobre los problemas reales de usabilidad del 
  						sitio web. En estas pruebas lo que se debe evaluar es el diseño a través de los usuarios, no al contrario.
  					</p></li><li class="listitem"><p>
  						Duración razonable: Si la tarea requiere demasiado tiempo para ser completada, sería recomendable descomponerla en subtareas
  					</p></li></ul></div><p>
  				Con los test de usuarios no sólo pretendemos detectar en qué momentos el usuario se equivoca o se detiene durante la realización de la tarea, 
  				sino también el porqué: qué es aquello que no entiende o qué le ha llevado a tomar decisiones equivocadas. Una forma de obtener esta 
  				información es mediante el protocolo <span xml:lang="en" class="foreignphrase"><em xml:lang="en" class="foreignphrase">think-aloud</em></span> o “pensamiento en voz alta”, que consiste en 
  				solicitar al participante que exprese verbalmente durante la prueba qué está pensando, qué no entiende, por qué lleva a cabo una acción o 
  				duda. No obstante, este protocolo tiene algunos inconvenientes, como el hecho de contar lo que uno hace y por qué lo hace inevitablemente 
  				altera la forma en la que se hacen las cosas (en comparación con cómo se harían en circunstancias normales). Una alternativa es el método 
  				“<span xml:lang="en" class="foreignphrase"><em xml:lang="en" class="foreignphrase">think-aloud</em></span> retrospectivo”, en el que el participante primero realiza la tarea y, una vez 
  				finalizada, expresa verbalmente cómo recuerda que ha sido su proceso interactivo.
  			</p><p>
  				Una vez los participantes finalicen la prueba y se haya registrado toda la información pertinente, se procede a analizar los resultados y 
  				sintetizarlos en un informe final, concluyendo qué mejoras necesita el diseño en base a estos resultados.
  			</p></div><div class="section" title="4.2.1.3. Cuándo"><div class="titlepage"><div><div><h3 class="title"><a id="d0e1331"/>4.2.1.3. Cuándo</h3></div></div></div><p>
  				Aunque los test de usuarios son pruebas de evaluación, no debemos por esto creer que deben llevarse a cabo una vez ha finalizado el proceso 
  				de diseño, desarrollo e implantación del producto. Recordemos que el DCU es una filosofía de diseño iterativa basada en la mejora incremental 
  				del producto. Por tanto, cuanto más esperamos para realizar la primera de las pruebas, más costoso resultará la reparación de los errores de 
  				diseño que se detecten.
  			</p><p>
  				En las etapas más tempranas del proyecto, ya que el producto aún no ha tomado forma, los test de usuarios deben realizarse sobre prototipos 
  				(modelos desechables elaborados específicamente para la evaluación de las decisiones de diseño). Estos prototipos pueden realizarse en papel 
  				(Medero; 2007), en HTML (Ramsay; 2009), o mediante aplicaciones específicas como Axure (véase el siguiente apartado sobre 
  				<span xml:lang="en" class="foreignphrase"><em xml:lang="en" class="foreignphrase">
                     <a class="xref" href="ch04s03.html#ch04c3" title="4.3.3. Documentos de diseño">Sección 4.3.3, “Documentos de diseño”</a>
                  </em></span>).
  			</p></div><div class="section" title="4.2.1.4. Limitaciones y problemas"><div class="titlepage"><div><div><h3 class="title"><a id="d0e1343"/>4.2.1.4. Limitaciones y problemas</h3></div></div></div><p>
  				El primer problema de los test de usuarios es el alto coste que implica tanto el reclutamiento de los participantes, como el tiempo y esfuerzo 
  				dedicados a realizar las pruebas y a sintetizar y analizar los resultados. Para reducir costes se recomienda realizar una evaluación heurística 
  				(véase el siguiente apartado) de forma previa a la prueba con usuarios, una técnica más económica que nos permite detectar una gran cantidad de 
  				problemas de usabilidad sin necesidad de implicar a usuarios. No obstante, el coste de las pruebas con usuarios se justifica por el retorno de 
  				inversión derivado (<span xml:lang="en" class="foreignphrase"><em xml:lang="en" class="foreignphrase">ROI: Return of Investment</em></span>) (Marcus; 2002).
  			</p><p>
  				El otro problema es que, al tratarse de pruebas que se realizan en laboratorio y en las que los objetivos y tareas se les imponen explícitamente 
  				a los participantes, la interacción del usuario se encuentra descontextualizada, influyendo en su forma de resolver problemas. Por ejemplo, 
  				Nielsen (1997) afirmaba que los resultados de sus estudios de usabilidad mostraban que más de la mitad de los usuarios se dirigían directamente 
  				al buscador interno para resolver sus necesidades cuando visitaban un sitio web, un dato que difícilmente se corresponde con el uso real de los 
  				buscadores internos que podemos observar analizando las estadísticas de un sitio web (véase apartado sobre <a class="xref" href="ch04s02.html#ch04b6c" title="4.2.6.3. Analítica Web">Sección 4.2.6.3, “Analítica Web”</a>).
  			</p><div class="informalfigure"><a id="fig28"/><div class="mediaobject"><img src="resource/INF-3-032.jpg" alt="Limitaciones y problemas"/><div class="caption"><p>
			  				Escena de un test de usuarios. Fuente (Elten; 2008)
			  			</p></div></div></div></div></div><div class="section" title="4.2.2. Evaluación heurística"><div class="titlepage"><div><div><h2 class="title"><a id="ch04b2"/>4.2.2. Evaluación heurística</h2></div></div></div><div class="section" title="4.2.2.1. Qué"><div class="titlepage"><div><div><h3 class="title"><a id="d0e1365"/>4.2.2.1. Qué</h3></div></div></div><p>
  				No todas las técnicas de DCU requieren la participación de usuarios, resultando de esta forma más económicas. Tal es el caso de los métodos 
  				de evaluación por inspección como la evaluación heurística, propuesta originalmente por Molich y Nielsen (1990).
  			</p><p>
  				En esta técnica varios expertos inspeccionan y analizan el diseño en busca de potenciales problemas de usabilidad, comprobando para ello el 
  				cumplimiento de principios de diseño usable (principios heurísticos) previamente establecidos. Estos principios de diseño o “heurísticas” 
  				son directrices que establecen requisitos que debe cumplir el diseño con el fin de facilitar su comprensión y uso por el usuario final.
  			</p></div><div class="section" title="4.2.2.2. Cómo"><div class="titlepage"><div><div><h3 class="title"><a id="d0e1372"/>4.2.2.2. Cómo</h3></div></div></div><p>
  				El número ideal de expertos que deben participar en la evaluación debe ser entre 3 y 5. Cada uno de los evaluadores examinará el diseño de forma 
  				independiente, documentando los problemas de usabilidad detectados. Una vez finalicen su trabajo, harán una puesta en común de los problemas, 
  				y se procederá a elaborar un informe final consensuado. Si la evaluación se hace con menos de tres evaluadores, muchos problemas de usabilidad 
  				quedarán sin detectar, y usar más de 5 aumentaría el coste de la evaluación sin ofrecer resultados que los justificasen (Nielsen; 1994).
  			</p><p>
  				Respecto al perfil de los revisores, aunque no es imprescindible que sean expertos en usabilidad, diferentes estudios demuestran que conforme 
  				más experiencia tengan, mayor será el número de problemas que puedan detectar (González, Pascual, Lorés; 2006).
  			</p><p>
  				Durante la prueba, los revisores no sólo deben identificar problemas de usabilidad, sino también ponderar la gravedad de esos problemas, 
  				tanto en términos de frecuencia y persistencia del problema, como del impacto o consecuencias que tendrá para el usuario (Manchón; 2003).
  			</p><p>
  				Como indica Villa (2003), el revisor puede acometer la evaluación en dos capas:
  			</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>
  						Evaluación de alto nivel: examinando el aspecto y comportamiento de la interfaz desde un punto de vista de tareas y objetivos, 
  						procesos y pasos...
  					</p></li><li class="listitem"><p>
  						Evaluación en detalle: centrada en aspectos concretos de la interfaz. Pantalla por pantalla, analizaremos en detalle el interfaz 
  						atendiendo a puntos como el carácter autoexplicativo de la información, ubicación de la misma, controles, textos, accesos a sistema 
  						de ayuda, etc.
  					</p></li></ul></div><p>
  				Numerosos autores han propuesto conjuntos de principios heurísticos o reglas de diseño que pueden ser empleadas como heurísticas 
  				(Schneiderman; 1986) (Nielsen; 1994) (Tognazzini; 2003). Otros autores (Hassan-Montero, Martín-Fernández; 2003b) (Márquez-Correa; 2003) 
  				(Marcos, Cañada; 2003) ofrecen guías compuestas por criterios heurísticos más específicos que los principios heurísticos, y por tanto de 
  				más fácil aplicación por evaluadores no expertos. Además, el lector puede revisar numerosos trabajos que nos ofrecen casos prácticos de 
  				aplicación de evaluación heurística (Marcos et al.; 2006) (García-Gómez; 2008) (Candamil-Llano; Guevara-Hurtado; 2009a).
  			</p></div><div class="section" title="4.2.2.3. Cuándo"><div class="titlepage"><div><div><h3 class="title"><a id="d0e1392"/>4.2.2.3. Cuándo</h3></div></div></div><p>
  				La evaluación heurística, por lo sencillo y económico de su proceso, puede llevarse a cabo en cualquier momento del ciclo de desarrollo 
  				del proyecto. Como indicábamos en el apartado sobre test de usuarios, un momento idóneo para su realización es antes de estas pruebas 
  				con usuarios, aunque esto no significa que siempre que realicemos una evaluación heurística debamos seguidamente llevar a cabo un test 
  				con usuarios.
  			</p><p>
  				Dependiendo del momento de aplicación de la evaluación heurística, los principios o criterios a comprobar podrían variar. En las etapas 
  				más tempranas se suelen verificar criterios relacionados con la arquitectura de información, mientras que en etapas posteriores, cuando 
  				el diseño se encuentra más elaborado, entrarán en juego también principios de diseño gráfico o visual.
  			</p></div><div class="section" title="4.2.2.4. Limitaciones y problemas"><div class="titlepage"><div><div><h3 class="title"><a id="d0e1399"/>4.2.2.4. Limitaciones y problemas</h3></div></div></div><p>
  				González, Pascual y Lorés (2006), tras una revisión exhaustiva de la literatura científica sobre evaluación heurística, resumen los 
  				problemas o desventajas destacados por diferentes autores, entre los que podemos encontrar los siguientes:
  			</p><p>
  				La evaluación heurística permite identificar una mayor cantidad de problemas de usabilidad menores, pero una menor cantidad de problemas 
  				de usabilidad mayores que otras metodologías como los test de usuarios. Esto significa que esta metodología no puede sustituir a la 
  				realización de test de usuarios, ya que resulta menos eficaz en la detección de aquellos problemas de usabilidad que mayor impacto 
  				tendrán en el usuario final.
  			</p><p>
  				La evaluación heurística puede reportar falsas alarmas. Es decir, identificar como un problema de usabilidad aquello que realmente 
  				no lo es.
  			</p><p>
  				Aunque se trata de una técnica económica, para que ofrezca resultados realmente relevantes deberían participar varios evaluadores, 
  				por lo que tampoco es una técnica exenta de coste.
  			</p></div></div><div class="section" title="4.2.3. Card sorting"><div class="titlepage"><div><div><h2 class="title"><a id="ch04b3"/>4.2.3. Card sorting</h2></div></div></div><div class="section" title="4.2.3.1. Qué"><div class="titlepage"><div><div><h3 class="title"><a id="d0e1413"/>4.2.3.1. Qué</h3></div></div></div><p>
  				Como vimos en el apartado sobre modelos mentales, el conocimiento que los usuarios adquieren y registran a partir de su experiencia lo 
  				estructuran internamente en forma de conceptos y relaciones semánticas, pudiendo de esta forma recuperar y aplicar ese conocimiento en 
  				su actividad diaria.
  			</p><p>
  				Cuando diseñamos arquitecturas de información, siempre y cuando esas arquitecturas no deban cumplir una función didáctica (como pudiera 
  				ser el caso de la arquitectura de información de una enciclopedia online), deben adaptarse al modelo mental del usuario. El arquitecto 
  				de información, por tanto, tiene un rol de traductor, cuya tarea principal es transformar el modelo organizativo de la empresa o institución 
  				que pretende su proyección online (sitio web), al modelo mental de los usuarios a los que se dirige.
  			</p><p>
  				Si bien extraer el modelo mental y objetivos del cliente es una tarea relativamente fácil (por ejemplo, por medio de simples entrevistas), 
  				extraer el modelo mental del usuario para adaptar la organización y clasificación de información a dicho modelo, resulta una tarea más 
  				compleja. Una de las técnicas más populares y eficaces para elicitar o extraer la estructura semántica del conocimiento que los usuarios 
  				tienen sobre un dominio concreto, es la llamada <span xml:lang="en" class="foreignphrase"><em xml:lang="en" class="foreignphrase">card sorting</em></span> o “Agrupación de tarjetas”.
  			</p><p>
  				Esta técnica consiste en solicitar a un grupo de participantes –que como en el caso del test de usuarios deben tener un perfil acorde con 
  				la audiencia a la que se dirige el sitio– que agrupen los conceptos representados en cada tarjeta por su similitud semántica. El objetivo 
  				es, por tanto, identificar qué conceptos, de los representados en cada tarjeta, tienen relación semántica entre sí, e incluso cuál es el 
  				grado de esa relación.
  			</p></div><div class="section" title="4.2.3.2. Cómo"><div class="titlepage"><div><div><h3 class="title"><a id="d0e1427"/>4.2.3.2. Cómo</h3></div></div></div><p>
  				Lo primero que debemos decidir al planificar una prueba de <span xml:lang="en" class="foreignphrase"><em xml:lang="en" class="foreignphrase">card sorting</em></span> es si vamos a realizar 
  				un análisis cualitativo de los resultados o uno cuantitativo, ya que esto influirá tanto en el número de participantes como en la forma de 
  				dirigir la prueba.
  			</p><p>
  				En el análisis cualitativo, el número de participantes debe encontrarse en torno de 5. De esta forma podremos acompañar a cada participante 
  				en su tarea, e interrogarle acerca de por qué toma la decisión de agrupar unos conceptos u otros y con qué problemas de comprensión se 
  				encuentra durante la prueba (Carreras-Plaza, Guaderrama-Hernández; 2004) (Ortega-Santamaría; 2005).
  			</p><p>
  				Con el análisis cuantitativo, por el contrario, lo que buscamos es una imagen global de las relaciones semánticas entre conceptos. No 
  				buscamos tanto un conocimiento en detalle de cómo los usuarios entienden que se relacionan los conceptos, como obtener las relaciones 
  				semánticas compartidas y colectivamente más reforzadas que tienen los conceptos para la audiencia del sitio web. En este tipo de análisis, 
  				para que los resultados sean representativos, debemos contar con un número mayor de participantes, que Tullis y Wood (2004) estiman entre 20 y 30.
  			</p><p>
  				Otra de las decisiones que debemos tomar en la planificación de la prueba es el tipo de <span xml:lang="en" class="foreignphrase"><em xml:lang="en" class="foreignphrase">card sorting</em></span> 
  				que llevaremos a cabo, en función de su propósito. Rosenfeld y Morville (2002) diferencian entre <span xml:lang="en" class="foreignphrase"><em xml:lang="en" class="foreignphrase">card sorting</em></span> 
  				abierto y cerrado. En el abierto el usuario puede agrupar los conceptos libremente en el número de conjuntos que crea necesario, mientras que en 
  				el cerrado los grupos o conjuntos están predefinidos y etiquetados, y el participante únicamente deberá ubicar cada concepto en el grupo que 
  				crea pertinente. El <span xml:lang="en" class="foreignphrase"><em xml:lang="en" class="foreignphrase">card sorting</em></span> cerrado es recomendable para evaluar si una categorización resulta 
  				predecible para el usuario, mientras que el abierto tiene el objetivo de descubrir qué tipo de categorización o agrupación de los conceptos 
  				resultará más natural y acorde con el modelo mental compartido de la audiencia del sitio web. En el trabajo de Hassan-Montero et al. (2004), 
  				podemos ver descrito un caso práctico de card sorting abierto, mientras que Candamil-Llano y Guevara-Hurtado (2008) nos ofrecen un caso de 
  				<span xml:lang="en" class="foreignphrase"><em xml:lang="en" class="foreignphrase">card sorting</em></span> cerrado.
  			</p><p>
  				En el análisis cuantitativo de los resultados de <span xml:lang="en" class="foreignphrase"><em xml:lang="en" class="foreignphrase">card sorting</em></span> (abierto) entran en juego multitud de 
  				técnicas estadísticas, que comparten el objetivo de reducir la matriz NxN (N es el número de conceptos) donde se representa el número de 
  				participantes que han colocado en un mismo grupo cada par posible de categorías, a representaciones gráficas que faciliten al evaluador 
  				analizar las relaciones semánticas entre conceptos, y en algunos casos el peso de esas relaciones (Hassan-Montero et al.; 2004). Entre las 
  				técnicas que podemos utilizar se encuentran el escalamiento multidimensional (MDS: <span xml:lang="en" class="foreignphrase"><em xml:lang="en" class="foreignphrase">Multidimensional Scaling</em></span>), 
  				la técnica de poda <span xml:lang="en" class="foreignphrase"><em xml:lang="en" class="foreignphrase">Pathfinder</em></span> (PFNets), el Análisis de Clusters (<span xml:lang="en" class="foreignphrase"><em xml:lang="en" class="foreignphrase">clustering</em></span>), 
  				el Análisis de Componentes Principales (<span xml:lang="en" class="foreignphrase"><em xml:lang="en" class="foreignphrase">PCA: Principal Component Analysis</em></span>), o la Redes Neuronales 
  				Artificiales (Herrero-Solana, Hassan-Montero; 2006). Como señalan Antolí et al. (2005), la más popular y conocida entre los profesionales de 
  				la experiencia de usuario es el análisis de <span xml:lang="en" class="foreignphrase"><em xml:lang="en" class="foreignphrase">clusters</em></span>.
  			</p><p>
  				Las pruebas de <span xml:lang="en" class="foreignphrase"><em xml:lang="en" class="foreignphrase">card sorting</em></span> pueden ser realizadas de forma manual o virtual. En el primer caso 
  				(<a class="xref" href="ch04s02.html#fig29">Fig 29</a>), los conceptos son representados en tarjetas reales (papel o cartón), y los participantes 
  				proceden a agruparlas sobre una mesa. En el segundo caso se emplean aplicaciones software específicas, mediante las que los participantes 
  				realizan la prueba (ejemplos de aplicaciones populares son <a class="link" href="http://optimalsort.com">http://optimalsort.com</a> y <a class="link" href="http://websort.net">http://websort.net</a>). 
  				La ventaja principal de usar estas aplicaciones es que automatizan y facilitan la recogida de datos y su análisis estadístico, por lo que son 
  				más recomendables cuando el propósito es el análisis cuantitativo. Como desventaja podemos señalar que, como nos indica nuestra experiencia 
  				personal llevando a cabo numerosas pruebas de <span xml:lang="en" class="foreignphrase"><em xml:lang="en" class="foreignphrase">card sorting</em></span>, los participantes suelen encontrar 
  				más divertido el <span xml:lang="en" class="foreignphrase"><em xml:lang="en" class="foreignphrase">card sorting</em></span> manual, y por tanto suelen estar más concentrados durante la tarea.
  			</p><div class="informalfigure"><a id="fig29"/><div class="mediaobject"><img src="resource/INF-3-033.jpg" alt="Cómo"/><div class="caption"><p>
			  				Participante repartiendo tarjetas. Fuente (García-Gómez; 2005).
			  			</p></div></div></div><p>
		  		En las pruebas de <span xml:lang="en" class="foreignphrase"><em xml:lang="en" class="foreignphrase">card sorting</em></span> hay pequeños detalles que pueden influir y condicionar 
		  		enormemente la forma en que los participantes realicen el ejercicio, y por tanto el resultado final de la prueba. Por ejemplo, el orden en 
		  		que se presenten las diferentes tarjetas puede influir en el tipo de agrupaciones que realizará el usuario, tal y como explican Antolí 
		  		et al. (2005). En pruebas manuales, como sugiere García-Gómez (2005), el tamaño de la mesa podría influir en el número máximo de tarjetas 
		  		que el participante asignará a cada grupo. En nuestra experiencia con este tipo de pruebas, además, hemos detectado que los participantes 
		  		tienen una tendencia natural a hacer agrupaciones por relación sintáctica, es decir, a ubicar automáticamente en un mismo grupo tarjetas 
		  		que tengan en común alguna palabra, aún cuando la relación semántica entre ambos conceptos no esté clara.
		  	</p><p>
		  		No obstante, el factor que en mayor grado puede influir en cómo ejecuten el ejercicio los participantes, es su comprensión acerca de qué 
		  		tienen que hacer y cómo deben hacerlo. En este sentido, Spencer y Warfel (2007) ofrecen una útil guía, que incluye un ejemplo de las 
		  		instrucciones que se deben dar a los participantes antes de dar comienzo a la prueba.
		  	</p><p>
		  		Hasta el momento hemos hablado de agrupar “conceptos”, sin establecer un vínculo claro con qué elementos del sitio web pudieran representar 
		  		estos “conceptos”. En las pruebas de <span xml:lang="en" class="foreignphrase"><em xml:lang="en" class="foreignphrase">card sorting</em></span> los “conceptos” suelen representar categorías 
		  		u opciones de navegación, y por tanto lo que se pretende con la prueba es extraer de los propios usuarios cuál sería la mejor forma de 
		  		agruparlas o clasificarlas, condicionando de este modo cómo los usuarios encontrarán estas opciones o categorías organizadas cuando 
		  		naveguen por sitio web.
		  	</p><p>
		  		Sin embargo, estos “conceptos” no siempre tienen por qué representar categorías u opciones de menús de navegación, ya que podrían representar 
		  		bloques de contenido de una misma página, permitiéndonos saber cómo ordenarlos espacialmente de acuerdo a su similitud semántica; o incluso 
		  		podrían representar productos que se vayan a ofrecer desde el sitio web.
		  	</p><p>
		  		Lo que se persigue, en gran medida, es lograr la coherencia local y global del contenido. Cuando el usuario salta desde una unidad de 
		  		información a otra lo hace porque ambas presentan una conexión semántica. A su vez, cada una de esas unidades de información es posible 
		  		interpretarla y comprenderla en función de sus relaciones temporales, causales y lógicas, que las relacionan con el contexto global.
		  	</p></div><div class="section" title="4.2.3.3. Cuándo"><div class="titlepage"><div><div><h3 class="title"><a id="d0e1513"/>4.2.3.3. Cuándo</h3></div></div></div><p>
  				El <span xml:lang="en" class="foreignphrase"><em xml:lang="en" class="foreignphrase">card sorting</em></span> es una prueba destinada a adaptar la arquitectura de información al modelo 
  				mental del usuario, por tanto tiene lugar en etapas tempranas del proyecto (arquitectura de información). Dado que el 
  				<span xml:lang="en" class="foreignphrase"><em xml:lang="en" class="foreignphrase">card sorting</em></span> abierto cumple la función de ayudar en la toma de decisiones organizativas, y 
  				el <span xml:lang="en" class="foreignphrase"><em xml:lang="en" class="foreignphrase">card sorting</em></span> cerrado cumple la función de evaluar esas decisiones, en el caso de que se 
  				realicen ambas pruebas, la abierta debe preceder a la cerrada. De hecho, ya que ambos tipos de <span xml:lang="en" class="foreignphrase"><em xml:lang="en" class="foreignphrase">card sorting</em></span> 
  				tienen propósitos diferentes y complementarios, su utilización combinada puede ofrecernos una imagen más fiel el modelo mental del usuario 
  				(García-Martín; 2008).
  			</p></div><div class="section" title="4.2.3.4. Limitaciones y problemas"><div class="titlepage"><div><div><h3 class="title"><a id="d0e1530"/>4.2.3.4. Limitaciones y problemas</h3></div></div></div><p>
  				Aunque muchos autores coinciden en afirmar que el <span xml:lang="en" class="foreignphrase"><em xml:lang="en" class="foreignphrase">card sorting</em></span> es un método rápido, fiable y 
  				barato (Sepencer, Warfel; 2007), coincidimos con Antolí et al. (2005) en que su uso inexperto o inadecuado puede producir resultados 
  				erróneos.
  			</p><p>
  				Por un lado, tal y como hemos visto, existen numerosos factores que, aún pareciendo poco significativos, pueden influir enormemente 
  				en los resultados que se obtengan.
  			</p><p>
  				Por otro lado, y como Antolí et al. (2005) comentan, de todas las opciones posibles para el análisis estadístico de resultados, en la 
  				mayoría de aplicaciones software de <span xml:lang="en" class="foreignphrase"><em xml:lang="en" class="foreignphrase">card sorting</em></span>, así como en los estudios publicados, 
  				suele aplicarse sólo una de las técnicas –análisis de <span xml:lang="en" class="foreignphrase"><em xml:lang="en" class="foreignphrase">clusters</em></span>–, y siempre uno de sus 
  				tipos, el <span xml:lang="en" class="foreignphrase"><em xml:lang="en" class="foreignphrase">clustering</em></span> determinista mediante técnicas “aglomerativas”.
  			</p><p>
  				No sólo existen más tipos de <span xml:lang="en" class="foreignphrase"><em xml:lang="en" class="foreignphrase">clustering</em></span>, sino que incluso entre las técnicas aglomerativas 
  				podemos diferenciar alrededor de 150 tipos en función de las reglas de aglomeración que utilicen (Herrero-Solana, Hassan-Montero; 2006). 
  				El problema está en que cada uno de estos tipos de análisis de clusters, aplicados sobre los mismos datos, podría ofrecer agrupaciones 
  				diferentes.
  			</p><p>
  				Con esto, no obstante, no pretendemos desanimar en el uso de esta técnica, ya que creemos que siempre obtendremos una visión más fiel 
  				del modelo mental de nuestros usuarios a través de una prueba de <span xml:lang="en" class="foreignphrase"><em xml:lang="en" class="foreignphrase">card sorting</em></span> –aún con 
  				errores– que sin llevar a cabo prueba alguna.
  			</p><p>
  				Por último señalar que, además del <span xml:lang="en" class="foreignphrase"><em xml:lang="en" class="foreignphrase">card sorting</em></span>, existen diversas técnicas estrechamente 
  				relacionadas, en cuanto que también están orientadas a extraer patrones de conocimiento semántico de los usuarios. Tal es el caso del 
  				“listado libre” (Sinha; 2003) o el “análisis de secuencia” (Ronda-León, Mesa-Rábade; 2005).
  			</p></div></div><div class="section" title="4.2.4. Eye-tracking"><div class="titlepage"><div><div><h2 class="title"><a id="ch04b4"/>4.2.4. Eye-tracking</h2></div></div></div><div class="section" title="4.2.4.1. Qué"><div class="titlepage"><div><div><h3 class="title"><a id="d0e1569"/>4.2.4.1. Qué</h3></div></div></div><p>
  				Como se puede deducir tras leer el apartado sobre <a class="xref" href="ch03.html#ch03a" title="3.1. Percepción visual">Sección 3.1, “Percepción visual”</a>, analizando una interfaz desde el 
  				conocimiento teórico sobre cómo las personas percibimos visualmente, podemos predecir en gran medida cuál será el comportamiento 
  				visual de los usuarios, detectando qué elementos atraerán su atención visual con más fuerza.
  			</p><p>
  				Por ejemplo, en función del tipo de elementos que esté buscando visualmente el usuario en cada instante (contenidos, navegación, mapa del 
  				sitio web, contacto…), será mayor la probabilidad de que atienda automáticamente a diferentes zonas de la página; un comportamiento que 
  				habrá interiorizado a partir de su experiencia previa navegando por otros sitios web. Igualmente sabemos que si un elemento es gráficamente 
  				inusual, si presenta características gráficas diferentes a las de sus elementos colindantes, éste atraerá con mayor fuerza la atención del 
  				usuario.
  			</p><p>
  				No obstante, las interfaces no suelen estar compuestas por formas gráficas simples. Un diseño puede presentar un alto grado de sofisticación 
  				visual, sin necesidad de que esto sea consecuencia de una complejidad artificial u ornamental. En estos casos, ser capaz de predecir qué 
  				mirará el usuario y en qué orden, se convierte en una actividad propia del mentalismo.
  			</p><p>
  				Desde el punto de vista empírico, existe un tipo de pruebas con usuarios que nos permiten estudiar y analizar su exploración visual, 
  				denominadas pruebas de <span xml:lang="en" class="foreignphrase"><em xml:lang="en" class="foreignphrase">eye-tracking</em></span> o de “seguimiento visual”. El concepto de 
  				<span xml:lang="en" class="foreignphrase"><em xml:lang="en" class="foreignphrase">eye-tracking</em></span> hace referencia a un conjunto de tecnologías (hardware y software) que permiten 
  				monitorizar y registrar la forma en la que una persona mira una determinada escena o imagen, en concreto en qué áreas fija su atención, 
  				durante cuánto tiempo y qué orden sigue en su exploración visual (Hassan-Montrero, Herrero-Solana; 2007).
  			</p></div><div class="section" title="4.2.4.2. Cómo"><div class="titlepage"><div><div><h3 class="title"><a id="d0e1588"/>4.2.4.2. Cómo</h3></div></div></div><p>
  				Desde el punto de vista procedimental, las pruebas de <span xml:lang="en" class="foreignphrase"><em xml:lang="en" class="foreignphrase">eye-tracking</em></span> resultan muy similares a los 
  				test con usuarios descritos anteriormente. La diferencia estriba en la tecnología usada para registrar el comportamiento del usuario, y en 
  				qué comportamiento se pretende analizar con mayor detalle: su exploración visual.
  			</p><div class="informalfigure"><a id="fig30"/><div class="mediaobject"><img src="resource/INF-3-034.jpg" alt="Cómo"/><div class="caption"><p>
			  				Comportamiento visual de cuatro ususarios diferentes sobre una misma página. Fuente: Nielsen (2007).
			  			</p></div></div></div><p>
		  		La mayoría de sistemas de <span xml:lang="en" class="foreignphrase"><em xml:lang="en" class="foreignphrase">eye-tracking</em></span> se basan en el uso de cámaras 
		  		(<span xml:lang="en" class="foreignphrase"><em xml:lang="en" class="foreignphrase">eye-trackers</em></span>) que proyectan rayos infrarrojos hacia uno o los dos ojos del participante, 
		  		infiriendo la zona de la escena visual que el usuario se encuentra atendiendo en cada momento. Podemos diferenciar dos clases de sistemas de 
		  		<span xml:lang="en" class="foreignphrase"><em xml:lang="en" class="foreignphrase">eye-tracking</em></span>: aquellos que se colocan en la cabeza del participante, y aquellos que registran su 
		  		movimiento ocular desde la distancia, normalmente ubicados y camuflados en el monitor. Estos últimos resultan menos intrusivos (Goldberg, 
		  		Wichansky; 2003), y por tanto más adecuados para la evaluación de interfaces, donde no resulta crucial que el usuario tenga completa libertad 
		  		para mover su cabeza.
		  	</p><p>
		  		Tras un breve proceso de calibración del sistema, el participante de la prueba puede dar comienzo a la realización de las tareas que le hayan 
		  		sido encomendadas, tiempo durante el cual el sistema monitorizará y registrará continuamente su movimiento ocular: fijaciones y “sacadas” 
		  		(estos conceptos fueron descritos en el apartado sobre <a class="xref" href="ch03.html#ch03a" title="3.1. Percepción visual">Sección 3.1, “Percepción visual”</a>).
		  	</p><p>
		  		Una vez finalizada la prueba, el software de <span xml:lang="en" class="foreignphrase"><em xml:lang="en" class="foreignphrase">eye-tracking</em></span> debe permitirnos analizar los resultados. 
		  		Para ello, suelen emplearse representaciones gráficas que resumen la ingente cantidad de información que cada participante ha generado con su 
		  		exploración visual. Para analizar el comportamiento visual de cada participante individualmente, se suelen utilizar representaciones gráficas 
		  		de su recorrido visual en forma de grafo lineal (<a class="xref" href="ch04s02.html#fig30">Fig 30</a>), donde cada nodo identifica una fijación, el 
		  		tamaño del nodo el tiempo de la fijación, y los conectores entre nodos el salto visual de una fijación a la siguiente.
		  	</p><p>
		  		Para analizar de forma agregada el comportamiento visual de un grupo de participantes, se suelen emplear <span xml:lang="en" class="foreignphrase"><em xml:lang="en" class="foreignphrase">“heatmaps”</em></span> 
		  		o mapas de calor, donde los colores de mayor intensidad señalan las zonas de la interfaz en las que los participantes han fijado su atención 
		  		con mayor frecuencia (<a class="xref" href="ch04s02.html#fig30">Fig 30</a>).
		  	</p></div><div class="section" title="4.2.4.3. Cuándo"><div class="titlepage"><div><div><h3 class="title"><a id="d0e1632"/>4.2.4.3. Cuándo</h3></div></div></div><p>
  				Las pruebas de <span xml:lang="en" class="foreignphrase"><em xml:lang="en" class="foreignphrase">eye-tracking</em></span> sólo pueden ofrecer información valiosa sobre diseños gráficos 
  				elaborados. Pequeños cambios en estos diseños (como cambiar el color de fondo de un bloque, o cambiar la ubicación de un elemento), pueden 
  				hacer que los patrones de exploración varíen, por lo que no es una técnica recomendable para su uso iterativo durante el ciclo de desarrollo 
  				del producto, sino sólo para su evaluación final.
  			</p><div class="informalfigure"><a id="fig31"/><div class="mediaobject"><img src="resource/INF-3-035.jpg" alt="Cuándo"/><div class="caption"><p>
			  				Mapas de color sobre tres interfaces diferentes. Fuente: Nielsen (2006b).
			  			</p></div></div></div></div><div class="section" title="4.2.4.4. Limitaciones y problemas"><div class="titlepage"><div><div><h3 class="title"><a id="d0e1647"/>4.2.4.4. Limitaciones y problemas</h3></div></div></div><p>
  				Los actuales sistemas de <span xml:lang="en" class="foreignphrase"><em xml:lang="en" class="foreignphrase">eye-tracking</em></span> disponibles en el mercado presentan en su mayoría un 
  				alto grado de precisión, fruto de la larga evolución que ha experimentado esta tecnología en las últimas décadas. Sin embargo, sigue 
  				siendo una tecnología cara, un hecho que impide una mayor difusión en el entorno profesional.
  			</p><p>
  				Otro problema es que, aunque el proceso de calibración visual de los participantes previo a la prueba es rápido y sencillo, existe un 
  				significativo porcentaje de personas cuyos ojos no pueden calibrarse (Jacob, Karn; 2003), lo que encarece aún más este tipo de estudios.
  			</p><p>
  				Como otras pruebas con usuarios descritas en este apartado, las pruebas de <span xml:lang="en" class="foreignphrase"><em xml:lang="en" class="foreignphrase">eye-tracking</em></span> requieren 
  				del evaluador un conocimiento y esfuerzo considerable en la interpretación de los resultados, por lo que su uso inexperto puede conducir a 
  				conclusiones erróneas. Una vez más, no obstante, defendemos que cualquier prueba con usuarios resulta más útil que no hacer prueba alguna, 
  				aún cuando se comentan errores de interpretación.
  			</p><p>
  				Por último señalar que las pruebas de eye-tracking ofrecen datos cualitativos escondidos bajo la apariencia de datos cuantitativos. 
  				Analizar una interfaz con 5 participantes generará una gran cantidad de datos, pero desde el punto de vista estadístico, sigue siendo 
  				una muestra de 5 sujetos.
  			</p></div></div><div class="section" title="4.2.5. Etnografía"><div class="titlepage"><div><div><h2 class="title"><a id="ch04b5"/>4.2.5. Etnografía</h2></div></div></div><div class="informalfigure"><a id="fig32"/><div class="mediaobject"><img src="resource/INF-3-036.jpg" alt="Etnografía"/><div class="caption"><p>
		  				Diagrama de la aproximación etnográfica.
		  			</p></div></div></div><div class="section" title="4.2.5.1. Qué"><div class="titlepage"><div><div><h3 class="title"><a id="d0e1674"/>4.2.5.1. Qué</h3></div></div></div><p>
	  			La etnografía constituye una rama de estudio de la antropología que busca estudiar y describir científicamente la conducta, el comportamiento, 
	  			las creencias y las acciones de los usuarios de una sociedad y una cultura específica. El investigador convive con los sujetos de la 
	  			investigación para comprender, por propia experiencia y observación directa, el ámbito sociocultural donde están inmersos.
	  		</p><p>
	  			Es un campo de estudio que emplea principalmente métodos cualitativos, con el objetivo de ayudarnos a descubrir y comprender el comportamiento 
	  			social de nuestros usuarios. Sus métodos nos permiten predecir o explicar acciones e interacciones que, de otro modo, podrían quedar aisladas 
	  			y provocar resultados contrarios a los objetivos propuestos en nuestro sitio.
	  		</p><p>
	  			Los estudios etnográficos nos acercan a un conjunto de valoraciones (sociales, culturales, idiomáticas, actitudinales, mentales…) relacionadas 
	  			con el contexto de uso, que son incluidas en el proceso y que proporcionan, necesariamente, una garantía sobre la objetividad y certeza de 
	  			explicaciones o descripciones que se hagan sobre dicho contexto.
	  		</p></div><div class="section" title="4.2.5.2. Cómo"><div class="titlepage"><div><div><h3 class="title"><a id="d0e1683"/>4.2.5.2. Cómo</h3></div></div></div><p>
	  			Este tipo de investigación no es utilizada para validar o invalidar hipótesis generales, porque todo depende, como decíamos antes, del 
	  			contexto de uso y de la gestión de significados.
	  		</p><p>
	  			Con las técnicas etnográficas observamos a las personas en situaciones reales, contextos naturales que nos permiten examinar y analizar 
	  			sus experiencias y ver el sentido que tienen en sus vidas. Esto no significa que estemos estudiando concretamente a las personas. Son su 
	  			entorno, su actividad, su situación o los procesos e interacciones que llevan a cabo, el objeto de nuestro análisis.
	  		</p><p>
	  			Podemos optar por estudios prolongados, que requerirán de un análisis más detallado de las observaciones realizadas, materiales audiovisuales 
	  			y datos recogidos, o por una etnografía rápida (Norman; 2000) (Millen; 2000) que podrá afectar a la reducción de tiempos, objetivos, equipo 
	  			de trabajo o recursos empleados. Dependiendo de la aproximación etnográfica que empleemos, el material empírico y analítico (Dourish; 2006) 
	  			se verá ampliado o reducido condicionando la transferencia y utilización de los resultados.
	  		</p><p>
	  			En cualquier caso el observador no deberá comportarse como un simple grabador de eventos. Actúa como un observador que, sin afectar ni ser 
	  			afectado por el entorno, reconoce la situación de observación, percibe, recoge y descifra lo explícito e implícito, para ofrecer una 
	  			representación fiel que facilite el proceso analítico.
	  		</p><p>
	  			La forma de hacerlo puede ser a partir de diarios de campo, anotaciones, documentación extraída del propio contexto o bien a partir de métodos 
	  			y técnicas de indagación, que permiten recoger de los usuarios sus opiniones y experiencias (en posteriores apartados describiremos la 
	  			entrevista, una de las técnicas más utilizadas en combinación con otras).
	  		</p></div><div class="section" title="4.2.5.3. Cuándo"><div class="titlepage"><div><div><h3 class="title"><a id="d0e1696"/>4.2.5.3. Cuándo</h3></div></div></div><p>
	  			Un estudio etnográfico nos aporta datos cualitativos que debemos organizar, comprender e interpretar en fases tempranas, anteriores al proceso 
	  			de diseño del producto. Aun así, la información obtenida tendrá la función de servir de referencia en posteriores etapas de diseño y desarrollo.
	  		</p><p>
	  			Sin embargo, estos estudios no pueden condicionar el ritmo de producción ni alzarse como instrumentos imprescindibles que retrasen la labor 
	  			del equipo de trabajo. Norman (2006) cree que es importante separar las observaciones y estudios de campo del diseño conceptual y del 
	  			análisis de necesidades. Deberían quedar fuera del proceso y tomarse en consideración en la medida que aporten consistencia y reflejen 
	  			aspectos cruciales, pero no pueden condicionar el ritmo de trabajo o el comienzo del diseño.
	  		</p></div><div class="section" title="4.2.5.4. Limitaciones y problemas"><div class="titlepage"><div><div><h3 class="title"><a id="d0e1703"/>4.2.5.4. Limitaciones y problemas</h3></div></div></div><p>
	  			Mientras que las técnicas descritas hasta el momento tienen una relación más inmediata con la calidad del producto, la investigación etnográfica 
	  			se enfrenta a serios desafíos para superar la validez y pragmatismo de sus métodos. Su posición frente a otros métodos de DCU puede verse como 
	  			una diferenciación entre validar para lograr la calidad deseada o inspirar para llevar a cabo el diseño (Gilmore; 2002). Pero aún cuando el 
	  			objetivo principal de la etnografía es la inspiración, no es menos cierto que los equipos de diseño encuentran dificultades para aprovechar 
	  			y aplicar en su trabajo los resultados extraídos del mundo real.
	  		</p><p>
	  			Se plantea así una disyuntiva. Por un lado aceptamos que el diseño debe atender al contexto y a los aspectos sociales que influyen en el 
	  			comportamiento de nuestros usuarios. Pero por otro, encontramos dificultades para integrar la investigación y las metodologías de trabajo en 
	  			el proceso. Para Räsänen y Nyce (2006) el problema se produce cuando los desarrolladores y diseñadores usan la etnografía como un instrumento 
	  			para identificar y resolver problemas o para extraer datos estadísticos, en vez de para predecir y explicar resultados. Esto conlleva que 
	  			reduzcamos todo su potencial al considerarlo un método para producir respuestas a preguntas específicas, en vez de para descubrir necesidades, 
	  			comportamientos y actitudes.
	  		</p><p>
	  			Por otra parte, mientras que las investigaciones etnográficas son lentas y requieren tiempo y esfuerzo en la observación e interpretación, la 
	  			tendencia actual en el entorno profesional es la de reducir y acelerar los ciclos de desarrollo de productos al máximo. En consecuencia, 
	  			resulta complicada tanto su aplicación, como su aplicación correcta.
	  		</p><p>
	  			Atender a grupos excesivamente amplios también puede verse como un problema o limitación. La etnografía debe trabajar con grupos relativamente 
	  			pequeños, ya que el observador puede que no realice su trabajo correctamente y acabe por recoger tal cantidad de datos que difuminen las 
	  			posibilidades argumentativas o interpretativas de los mismos.
	  		</p></div></div><div class="section" title="4.2.6. Otras técnicas destacables"><div class="titlepage"><div><div><h2 class="title"><a id="ch04b6"/>4.2.6. Otras técnicas destacables</h2></div></div></div><p>
  			Además de las técnicas descritas, existen muchas otras que ofrecen información muy valiosa acerca de los usuarios. Sin embargo, debido a las 
  			limitaciones del presente trabajo, no todas pueden ser tratadas con el mismo nivel de detalle. Por tanto, a continuación ofrecemos una breve 
  			descripción de otras técnicas de valor destacable en DCU.
  		</p><div class="section" title="4.2.6.1. Entrevistas"><div class="titlepage"><div><div><h3 class="title"><a id="ch04b6a"/>4.2.6.1. Entrevistas</h3></div></div></div><p>
  				La información más valiosa sobre la usabilidad de un diseño la obtenemos observando el comportamiento de los usuarios, no preguntándoles. 
  				De hecho, revisando las técnicas que involucran a usuarios descritas hasta el momento, comprobaremos que están orientadas principalmente 
  				a obtener información objetiva (qué hacen los participantes), y en mucho menor grado información subjetiva (qué dicen).
  			</p><p>
  				Cuando Nielsen (2001) afirma que la primera regla de usabilidad es no escuchar a los usuarios, no le falta razón. Como señala el autor, 
  				cuando se le pregunta a un usuario acerca de un diseño, su respuesta estará motivada por lo que cree debería responder o quiere ser oído 
  				por quien pregunta. Además, si se nos pregunta sobre el porqué de nuestro comportamiento (en este contexto, usando una aplicación), las 
  				personas tendemos a racionalizarlo, a completar, reinventar y reinterpretar nuestros recuerdos, y a buscar una causa, aunque la desconozcamos, 
  				a nuestras acciones pasadas.
  			</p><p>
  				Esto no significa que no podamos obtener información valiosa para el diseño preguntando a los usuarios. Las entrevistas con usuarios son una 
  				poderosa herramienta cualitativa, pero no para evaluar la usabilidad de un diseño, sino para descubrir deseos, motivaciones, valores y 
  				experiencias de nuestros usuarios (Kuniavsky; 2003).
  			</p><p>
  				Durante estas entrevistas, el entrevistador debe mostrarse neutral y no dirigir o condicionar las respuestas del entrevistado. Lo que 
  				pretendemos es descubrir información que nos oriente en el diseño, no confirmar nuestras propias creencias sobre cómo son los usuarios.
  			</p><p>
  				Una variante interesante de las entrevistas, son los <span xml:lang="en" class="foreignphrase"><em xml:lang="en" class="foreignphrase">focus group</em></span> (en español grupos focales 
  				o sesiones de grupo), en las que un moderador entrevista de forma conjunta a un grupo de usuarios, y donde la interacción entre los 
  				participantes nos ofrece información adicional sobre problemas, experiencias o deseos compartidos.
  			</p></div><div class="section" title="4.2.6.2. Encuestas"><div class="titlepage"><div><div><h3 class="title"><a id="ch04b6b"/>4.2.6.2. Encuestas</h3></div></div></div><p>
  				Hasta el momento, las técnicas descritas han sido esencialmente cualitativas. Estas técnicas nos ayudan a encontrar respuesta acerca de los 
  				problemas de usabilidad de nuestros diseños, cómo los usuarios interactúan y comprenden el diseño, e incluso qué pueden desear o necesitar. 
  				Sin embargo, por su naturaleza cualitativa, estas técnicas no nos permiten delimitar cómo son realmente nuestros usuarios, y en qué se 
  				diferencian del resto de la población.
  			</p><p>
  				Las encuestas representan una poderosa herramienta cuantitativa para conocer a nuestra audiencia, a través de preguntas estructuradas que 
  				deben ser respondidas por una proporción estadísticamente representativa de dicha audiencia. Estas preguntas suelen versar sobre cuestiones 
  				demográficas (cómo son), tecnológicas (cómo acceden a Internet), de necesidades y hábitos (cómo y para qué usan Internet), competitivas 
  				(qué sitios web suelen visitar), de satisfacción (acerca de nuestro producto), de preferencias (qué les gusta y qué no), y de deseos 
  				(qué echan en falta) (Kuniavsky; 2003).
  			</p><p>
  				El mayor error a cometer en la realización de una encuesta se encuentra en el sesgo que se puede producir en la delimitación de la muestra; 
  				es decir, a quién se invitará a participar, y qué subconjunto de los encuestados será considerado válido.
  			</p><p>
  				Por último, debemos recordar que las encuestas, al igual que las entrevistas, tampoco representan una herramienta fiable de evaluación de 
  				usabilidad, ya que su objetivo es otro.
  			</p></div><div class="section" title="4.2.6.3. Analítica Web"><div class="titlepage"><div><div><h3 class="title"><a id="ch04b6c"/>4.2.6.3. Analítica Web</h3></div></div></div><p>
  				La Analítica Web es definida como la medición, recolección, análisis y documentación de datos de Internet con el objetivo de comprender y 
  				optimizar el uso de la Web (WAA; 2009). Bajo el concepto de Analítica Web se engloba una gran cantidad de herramientas y técnicas de 
  				investigación, aunque sin duda la más definitoria es el análisis de datos reales de uso del sitio web, ya sea a través de los datos 
  				recogidos en “ficheros log” desde el lado del servidor, o a través de aplicaciones de monitorización javascript desde el lado del 
  				cliente. Estas últimas ofrecen mayor cantidad de información sobre las acciones de los usuarios, lo que sumado al hecho del lanzamiento 
  				de herramientas gratuitas como Google Analytics, ha provocado que en los últimos años hayan ganado mucha popularidad.
  			</p><p>
  				Estas técnicas permiten un análisis cuantitativo de las acciones que el usuario realiza sobre un sitio web, pero su principal fortaleza es 
  				que, al contrario que otras técnicas cuantitativas, no se basan en muestras, sino en la monitorización del total de los usuarios que están 
  				haciendo uso del sitio web. Como consecuencia, se trata de una técnica fiable y muy económica, pues no hay sesgo ni necesidad de invertir 
  				en la identificación y reclutamiento de participantes.
  			</p><p>
  				Las herramientas de monitorización de uso obtienen y manejan una serie de métricas, a través de las que podemos analizar el comportamiento 
  				de nuestros usuarios, tales como (WAA; 2007): páginas vistas, visitantes, visitantes únicos, nuevos visitantes, duración de la visita, 
  				<span xml:lang="en" class="foreignphrase"><em xml:lang="en" class="foreignphrase">click-through</em></span>, etc.
  			</p><p>
  				Como argumenta Rovira-Samblancat (2007), existen muy diversas formas de aprovechar los datos que recogen estas herramientas a fin de 
  				mejorar la usabilidad de un sitio web, como: analizar dónde hacen clic los usuarios; comparar el número de abandonos y éxitos de una 
  				tarea entre dos páginas con la misma función pero diferente diseño; detectar en qué campo de un formulario se produce mayor número de 
  				abandonos; o analizar las rutas de navegación que siguen los usuarios.
  			</p><p>
  				Otra información de gran valor que podemos obtener a través de estas herramientas, de cara a mejorar la arquitectura de información del 
  				sitio web, es analizar el vocabulario utilizado por los usuarios en sus consultas a través del buscador interno del sitio web. De esta 
  				forma podemos estudiar, con datos reales y cuantitativos, el grado de correspondencia existente entre el vocabulario utilizado por los 
  				usuarios y el utilizado en el sitio web.
  			</p></div></div></div></body></html>